{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "#\n",
    "# The copyright of this file belongs to Feedzai. The file cannot be\n",
    "# reproduced in whole or in part, stored in a retrieval system,\n",
    "# transmitted in any form, or by any means electronic, mechanical,\n",
    "# photocopying, or otherwise, without the prior permission of the owner.\n",
    "#\n",
    "# (c) 2022 Feedzai, Strictly Confidential"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import lightgbm as lgbm  # Tested ML method\n",
    "import numpy as np       # Random number generation\n",
    "import seaborn as sns    # Plotting library\n",
    "import pandas as pd      # Read/write data\n",
    "import yaml              # Read hyperparameter space configuration\n",
    "\n",
    "from aequitas.group import Group                # Fairness metrics\n",
    "from matplotlib import pyplot as plt            # Plotting method\n",
    "from sklearn.preprocessing import LabelEncoder  # Categorical encoding for LGBM models\n",
    "from sklearn import metrics                     # ROC metrics\n",
    "\n",
    "from random_search import RandomValueTrial, suggest_callable_hyperparams  # Random search wrapper methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read hyperparameter space for the LGBM Models, expected structure is presented bellow\n",
    "with open(\"lightgbm_hyperparameter_space.yaml\", \"r\") as file:\n",
    "    hyperparam_space = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The expected structure is the following:\n",
    "hyperparam_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Testing a random search suggestion:\n",
    "trial = RandomValueTrial(seed=1)\n",
    "suggest_callable_hyperparams(trial, hyperparam_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define path to datasets. Replace `base_path` with the appropriate value.\n",
    "base_path = \"</path/to/datasets>\"\n",
    "\n",
    "datasets_paths = {\n",
    "    \"Base\":    base_path + \"Base.parquet\",\n",
    "    \"TypeI\":   base_path + \"TypeI.parquet\",\n",
    "    \"TypeII\":  base_path + \"TypeII.parquet\",\n",
    "    \"TypeIII\": base_path + \"TypeIII.parquet\",\n",
    "    \"TypeIV\":  base_path + \"TypeIV.parquet\",\n",
    "    \"TypeV\":   base_path + \"TypeV.parquet\",\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read the datasets with pandas.\n",
    "datasets = {key: pd.read_parquet(path) for key, path in datasets_paths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the label field and categorical columns.\n",
    "label = \"fraud_bool\"\n",
    "\n",
    "categorical_features = [\n",
    "    \"payment_type\",\n",
    "    \"employment_status\",\n",
    "    \"housing_status\",\n",
    "    \"source\",\n",
    "    \"device_os\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the train and test sets. Shuffle data with `sample` method.\n",
    "# The split was done by month. The first 6 months as the train, the last 2 months as test.\n",
    "train_dfs = {key: df[df[\"month\"]<6].sample(frac=1, replace=False) for key, df in datasets.items()}\n",
    "test_dfs = {key: df[df[\"month\"]>=6].sample(frac=1, replace=False) for key, df in datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Encode the categorical variables in the datasets to integers. \n",
    "# This is expected by LGBM (or columns with the `categorical` data type).\n",
    "\n",
    "for name in datasets.keys():  # For each dataset in the suite\n",
    "    train = train_dfs[name]\n",
    "    test = test_dfs[name]\n",
    "\n",
    "    for feat in categorical_features:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(train[feat])  # Fit an encoder to the train set.\n",
    "        train[feat] = encoder.transform(train[feat])  # Transform train set.\n",
    "        test[feat] = encoder.transform(test[feat])    # Transform test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cell with train loop.\n",
    "\n",
    "# Define number of trials in Random search.\n",
    "n_trials=100\n",
    "# Random state for sampling seeds.\n",
    "np.random.seed(42)\n",
    "# Seeds for the random search sampling algorithm.\n",
    "seeds = np.random.choice(list(range(1_000_000)), size=n_trials, replace=False)\n",
    "\n",
    "# Variable to store the results.\n",
    "runs = {}\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    seed = seeds[trial]\n",
    "    trial = RandomValueTrial(seed=seed)\n",
    "    # Hyperparameters for the random search trial.\n",
    "    test_hyperparams = suggest_callable_hyperparams(trial, hyperparam_space)\n",
    "    del test_hyperparams[\"classpath\"] # Remove unnecessary key in hyperparaemters.\n",
    "    \n",
    "    # Update list of tested hyperparameters.\n",
    "    prev_hyperparams = runs.get(\"hyperparams\", [])\n",
    "    prev_hyperparams.append(test_hyperparams)\n",
    "    runs[\"hyperparams\"] = prev_hyperparams\n",
    "    \n",
    "    for dataset_name in datasets.keys():  # Run hyperparameters on all variants of datastes.\n",
    "        model = lgbm.LGBMClassifier(n_jobs=10, **test_hyperparams)  # Instantiate LGBM Model.\n",
    "        X_train = train_dfs[dataset_name].drop(columns=[\"fraud_bool\"])\n",
    "        y_train = train_dfs[dataset_name][\"fraud_bool\"]\n",
    "        X_test = test_dfs[dataset_name].drop(columns=[\"fraud_bool\"])\n",
    "        y_test = test_dfs[dataset_name][\"fraud_bool\"]\n",
    "        # Fit model to training data.\n",
    "        model.fit(X_train, y_train, categorical_feature=categorical_features)\n",
    "        # Obtain predictions in test data.\n",
    "        predictions = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Obtain ROC curve for the predictions.\n",
    "        fprs, tprs, thresholds = metrics.roc_curve(y_test, predictions)\n",
    "        # Obtain threshold and recall. We select 5% FPR as threshold.\n",
    "        threshold = np.min(thresholds[fprs==max(fprs[fprs < 0.05])])\n",
    "        recall = np.max(tprs[fprs==max(fprs[fprs < 0.05])])\n",
    "\n",
    "        # Binarize predictions for Aequitas.\n",
    "        preds_binary = (predictions > threshold).astype(int)\n",
    "        \n",
    "        # Create a dataframe with protected group column, predictions and labels.\n",
    "        # Here, we select age>=50 as threshold.\n",
    "        aequitas_df = pd.DataFrame(\n",
    "            {\n",
    "                \"age\": (X_test[\"customer_age\"]>=50).map({True: \"Older\", False: \"Younger\"}),\n",
    "                \"preds\": preds_binary,\n",
    "                \"y\": y_test.values\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Obtain FPR results for different groups.\n",
    "        g = Group()\n",
    "        aequitas_results = g.get_crosstabs(aequitas_df, attr_cols=[\"age\"], score_col=\"preds\", label_col=\"y\")[0]\n",
    "        \n",
    "        # Store the results for the trained model\n",
    "        results = {}\n",
    "        results[\"recall\"] = recall\n",
    "        results[\"recall Older\"] = aequitas_results[aequitas_results[\"attribute_value\"] == \"Older\"][[\"tpr\"]].values[0][0]\n",
    "        results[\"recall Younger\"] = aequitas_results[aequitas_results[\"attribute_value\"] == \"Younger\"][[\"tpr\"]].values[0][0]\n",
    "        results[\"fpr Older\"] = aequitas_results[aequitas_results[\"attribute_value\"] == \"Older\"][[\"fpr\"]].values[0][0]\n",
    "        results[\"fpr Younger\"] = aequitas_results[aequitas_results[\"attribute_value\"] == \"Younger\"][[\"fpr\"]].values[0][0]\n",
    "        \n",
    "        # Store the results in the runs variable\n",
    "        prev_runs = runs.get(dataset_name, [])\n",
    "        prev_runs.append(results)\n",
    "        runs[dataset_name] = prev_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with the results for each model in each dataset.\n",
    "rs_results = pd.DataFrame(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Helper method to obtain the metric values for a given model.\n",
    "def get_results(results, variant, metric):\n",
    "    col = results[variant]\n",
    "    values = []\n",
    "    for idx, val in col.iteritems():\n",
    "        values.append(val[metric])\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Obtain the relevant metrics to plots from the dataframe.\n",
    "variants = list(datasets_paths.keys())\n",
    "\n",
    "plot_results = {\"Variant\": [], \"Recall\": [], \"FPR Ratio\": []}\n",
    "\n",
    "for variant in variants:\n",
    "    plot_results[\"Recall\"] += get_results(rs_results, variant, \"recall\")\n",
    "    # Obtain the FPR if both groups.\n",
    "    for fpr_younger, fpr_older in zip(get_results(rs_results, variant, \"fpr Younger\"), get_results(rs_results, variant, \"fpr Older\")):\n",
    "        # Calculate FPR ratio as higher fpr / lower fpr\n",
    "        if fpr_younger > fpr_older:\n",
    "            plot_results[\"FPR Ratio\"] += [fpr_older/fpr_younger]\n",
    "        else:\n",
    "            plot_results[\"FPR Ratio\"] += [fpr_younger/fpr_older]\n",
    "    plot_results[\"Variant\"] += [variant] * len(get_results(rs_results, variant, \"recall\"))\n",
    "\n",
    "# Create a dataframe for easier plots.\n",
    "plot_results = pd.DataFrame(plot_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a plot with the full results of the random search algorithm.\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\", {\"grid.linestyle\": \"--\"})\n",
    "\n",
    "sns.jointplot(data=plot_results, x=\"Recall\", y=\"FPR Ratio\", hue=\"Variant\")\n",
    "plt.ylim((0,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the final plot. Highlight the top models:\n",
    "top_n = 5\n",
    "top_models_base = plot_results.loc[plot_results['Variant'] == 'Base'].sort_values('Recall', ascending=False).head(top_n).index.values\n",
    "top_models = deepcopy(top_models_base)\n",
    "for i in range(1, 6):\n",
    "    top_models = np.r_[top_models, top_models_base + (100 * i)]\n",
    "\n",
    "plot_results['index'] = plot_results.index\n",
    "plot_results['is_top'] = plot_results.apply(lambda x: 1 if x['index'] in top_models else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\", {\"grid.linestyle\": \"--\", \"grid.alpha\":0.1})\n",
    "DPI = 200\n",
    "plt.rcParams['figure.dpi'] = DPI\n",
    "plt.rcParams['figure.figsize'] = (10,5)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "# LEFT PLOT\n",
    "sns.scatterplot(ax=ax1, data=plot_results.loc[(~plot_results.index.isin(top_models)), :], x=\"Recall\", y=\"FPR Ratio\", hue=\"Variant\", alpha=0.2)\n",
    "sns.scatterplot(ax=ax1, data=plot_results.loc[plot_results.index.isin(top_models), :], x=\"Recall\", y=\"FPR Ratio\", hue=\"Variant\", legend=False)\n",
    "ax1.set(\n",
    "    ylim=(0,1)\n",
    ")\n",
    "\n",
    "# RIGHT PLOT\n",
    "sns.scatterplot(ax=ax2, data=plot_results.loc[(~plot_results.index.isin(top_models)) & (plot_results[\"Variant\"].isin([\"Base\", \"Type II\", \"Type V\", \"Type IV\"])), :], x=\"Recall\", y=\"FPR Ratio\", hue=\"Variant\", alpha=0.2, palette=[sns.color_palette()[0], sns.color_palette()[2], sns.color_palette()[4], sns.color_palette()[5]], legend=False)\n",
    "sns.scatterplot(ax=ax2, data=plot_results.loc[(plot_results.index.isin(top_models)) & (plot_results[\"Variant\"].isin([\"Base\", \"Type II\", \"Type V\", \"Type IV\"])), :], x=\"Recall\", y=\"FPR Ratio\", hue=\"Variant\", palette=[sns.color_palette()[0], sns.color_palette()[2], sns.color_palette()[4], sns.color_palette()[5]], legend=False)\n",
    "ax2.set(\n",
    "    ylim=(0,0.4),\n",
    "    ylabel=\"\",\n",
    "    xticks=np.arange(0.2, 0.8, 0.1),\n",
    "    yticks=np.arange(0, 0.5, 0.1),\n",
    "    xlim=(0.2, 0.6),\n",
    ")\n",
    "\n",
    "rect = plt.Rectangle((0.2, 0.004), 0.4, 0.396, facecolor=(0.1, 0.1, 0.1, 0.05), edgecolor=\"grey\", linestyle=\"-\")\n",
    "ax1.add_patch(rect)\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "handles = list(handles) + [rect]\n",
    "labels = list(labels) + [\"Plot on the right\"]\n",
    "ax1.legend(handles, labels, title=\"Variant\")\n",
    "\n",
    "sns.move_legend(\n",
    "    ax1,\n",
    "    loc=\"lower center\",\n",
    "    bbox_to_anchor=[1.08, -0.32],\n",
    "    ncol=7\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}