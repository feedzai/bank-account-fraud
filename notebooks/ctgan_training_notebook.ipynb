{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "#\n",
    "# The copyright of this file belongs to Feedzai. The file cannot be\n",
    "# reproduced in whole or in part, stored in a retrieval system,\n",
    "# transmitted in any form, or by any means electronic, mechanical,\n",
    "# photocopying, or otherwise, without the prior permission of the owner.\n",
    "#\n",
    "# (c) 2022 Feedzai, Strictly Confidential"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "import ctgan\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import yaml\n",
    "\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "from dataclasses import dataclass, field\n",
    "from numpy import random\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from typing import Dict, Union\n",
    "\n",
    "from random_search import RandomValueTrial, suggest_callable_hyperparams"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e04e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURES = [\n",
    "    'source',\n",
    "    'payment_type',\n",
    "    'device_os',\n",
    "    'housing_status',\n",
    "    'employment_status',\n",
    "    'month'\n",
    "]\n",
    "\n",
    "BOOLEAN_FEATURES = [\n",
    "    'email_is_free',\n",
    "    'fraud_bool',\n",
    "    'foreign_request',\n",
    "    'keep_alive_session',\n",
    "    'phone_home_valid',\n",
    "    'phone_mobile_valid',\n",
    "    'has_other_cards',\n",
    "]\n",
    "\n",
    "N_RUNS = 4\n",
    "\n",
    "TARGET_FPR = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a774be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'run_dir': '<run_dir>',\n",
    "    'config_path': 'config-rs.yml',\n",
    "    'n_procs': 4,\n",
    "    'devices': [\"cuda:0\", \"cuda:1\", \"cuda:2\", \"cuda:3\"],\n",
    "    'log_level': \"DEBUG\",\n",
    "    'seed': 42,\n",
    "    'dry_run': False,\n",
    "    'dev_run': False,\n",
    "    'n_trials': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3dc347",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RunConfig:\n",
    "    \"\"\"Dataclass with required information to train a model.\"\"\"\n",
    "    model_id: int\n",
    "\n",
    "    train_df: pd.DataFrame = field(repr=False)\n",
    "    val_df: pd.DataFrame = field(repr=False)\n",
    "    discrete_columns: list\n",
    "\n",
    "    model_run_dir: str\n",
    "\n",
    "    config: Dict\n",
    "\n",
    "    seed: Union[int, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562312d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def configure_logging(log_arg):\n",
    "    received_level = getattr(logging, log_arg.upper(), None)\n",
    "\n",
    "    logging_level = received_level if received_level else logging.INFO\n",
    "\n",
    "    logging.basicConfig(\n",
    "        format='[ %(levelname)s ] %(asctime)s (%(process)s-%(processName)s) %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        level=logging_level\n",
    "    )\n",
    "\n",
    "    if not received_level:\n",
    "        logging.warning('Unknown logging level %s: Setting logging to INFO', log_arg.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d129f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_run_dir(run_dir):\n",
    "    if run_dir.exists():\n",
    "        logging.error('Run Directory already exists: \\'%s\\'', run_dir)\n",
    "        exit(1)\n",
    "\n",
    "    os.mkdir(run_dir)\n",
    "\n",
    "    logging.info('Run results stored at: \\'%s\\'', run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ba0bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_configurations(config_path):\n",
    "    logging.info('Reading configurations from %s', config_path)\n",
    "\n",
    "    with open(config_path, 'r') as f:\n",
    "        configs = yaml.safe_load(f)\n",
    "\n",
    "    return configs['data'], configs['sweep_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac75369",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(data_config):\n",
    "\n",
    "    logging.info('Loading train dataset from \\'%s\\'', data_config['train'])\n",
    "    logging.info('Loading validation dataset from \\'%s\\'', data_config['validation'])\n",
    "\n",
    "    train_df = pd.read_csv(data_config['train'], index_col=0)\n",
    "    val_df = pd.read_csv(data_config['validation'], index_col=0)\n",
    "\n",
    "    if 'keep' in data_config:\n",
    "        train_df = train_df[data_config['keep']]\n",
    "        val_df = val_df[data_config['keep']]\n",
    "    elif 'remove' in data_config:\n",
    "        train_df = train_df.drop(columns=data_config['remove'])\n",
    "        val_df = val_df.drop(columns=data_config['remove'])\n",
    "\n",
    "    discrete_columns = [f for f in CATEGORICAL_FEATURES + BOOLEAN_FEATURES if f in train_df.columns]\n",
    "\n",
    "    logging.info('Train Dataset: %s Features, %s Rows', len(train_df.columns), len(train_df))\n",
    "    logging.info('Validation Dataset: %s Features, %s Rows', len(val_df.columns), len(val_df))\n",
    "    logging.debug('Train Features: %s', list(train_df.columns))\n",
    "    logging.debug('Validation features: %s', list(val_df.columns))\n",
    "    logging.debug('Discrete columns: %s', discrete_columns)\n",
    "\n",
    "    return train_df, val_df, discrete_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbc778a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Just path functions\n",
    "\n",
    "def pad_int(model_id, zfill=3):\n",
    "    return str(model_id).zfill(zfill)\n",
    "\n",
    "def model_run_dir(run_dir, model_id):\n",
    "    return run_dir / pad_int(model_id)\n",
    "\n",
    "def config_path(model_run_dir, model_id):\n",
    "    return model_run_dir / f'config-{pad_int(model_id)}.yml'\n",
    "\n",
    "\n",
    "def model_path(model_run_dir, model_id):\n",
    "    return model_run_dir / f'model-{pad_int(model_id)}.pkl'\n",
    "\n",
    "\n",
    "def train_dataset_path(model_run_dir, model_id):\n",
    "    return model_run_dir / f'train-dataset-{pad_int(model_id)}.csv'\n",
    "\n",
    "\n",
    "def synthetic_dataset_path(model_run_dir, model_id):\n",
    "    return model_run_dir / f'synthetic-dataset-{pad_int(model_id)}.csv'\n",
    "\n",
    "\n",
    "def model_evaluation_path(model_run_dir, model_id):\n",
    "    return model_run_dir / f'evaluation-{pad_int(model_id)}.csv'\n",
    "\n",
    "\n",
    "def stdout_path(model_run_dir, model_id):\n",
    "    return model_run_dir / f'stdout-{pad_int(model_id)}.log'\n",
    "\n",
    "\n",
    "def stderr_path(model_run_dir, model_id):\n",
    "    return model_run_dir/ f'stderr-{pad_int(model_id)}.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df14aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_run_configs(\n",
    "        run_dir: str,\n",
    "        datasets_config: dict,\n",
    "        data_sweep_params: dict,\n",
    "        model_sweep_params: dict,\n",
    "        devices: list,\n",
    "        n_trials: int,\n",
    "        seed: int,\n",
    ") -> list:    \n",
    "    train_df, val_df, discrete_columns = load_data(datasets_config)\n",
    "\n",
    "    run_configs = []\n",
    "    \n",
    "    random.seed(seed)\n",
    "    seeds = random.randint(n_trials*1000, size=n_trials)\n",
    "    for i, seed  in enumerate(seeds, start=1):\n",
    "        # Method to random sample configurations\n",
    "        configs_data =  suggest_callable_hyperparams(RandomValueTrial(seed=seed), data_sweep_params)\n",
    "        configs_model = suggest_callable_hyperparams(RandomValueTrial(seed=seed), model_sweep_params['kwargs'])\n",
    "        configs_model['generator_dim'] = eval(configs_model['generator_dim'])\n",
    "        configs_model['discriminator_dim'] = eval(configs_model['discriminator_dim'])\n",
    "        configs_model['generator_decay'] = eval(configs_model['generator_decay'])\n",
    "        configs_model['discriminator_decay'] = eval(configs_model['discriminator_decay'])\n",
    "        configs_model['cuda'] = devices[i % len(devices)]\n",
    "        config = {\"data\": configs_data, \"model\": configs_model}\n",
    "        run_configs.append(\n",
    "            RunConfig(\n",
    "                model_id=i,\n",
    "                train_df=train_df,\n",
    "                val_df=val_df,\n",
    "                discrete_columns=discrete_columns,\n",
    "                model_run_dir=model_run_dir(run_dir, i),\n",
    "                config=config,\n",
    "                seed=seed,\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    return run_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26892c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def subsample_with_prevalence(df, prevalence, seed):\n",
    "    if prevalence:\n",
    "        fraud = df[df['fraud_bool'] == 1]\n",
    "        non_fraud = df[df['fraud_bool'] == 0]\n",
    "\n",
    "        fraud_proportion, non_fraud_proportion = prevalence\n",
    "        non_fraud_instances = (len(fraud) * non_fraud_proportion) // fraud_proportion\n",
    "        if non_fraud_instances >= len(non_fraud):\n",
    "            logging.warning(\n",
    "                'Unable to subsample dataframe: Expected more than %s negative examples but got %s',\n",
    "                non_fraud_instances,\n",
    "                len(fraud)\n",
    "            )\n",
    "            non_fraud_sample = non_fraud\n",
    "        else:\n",
    "            non_fraud_sample = non_fraud.sample(n=non_fraud_instances, random_state=seed)\n",
    "        return utils.shuffle(pd.concat((fraud, non_fraud_sample)), random_state=seed)\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea34395",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_config_to_data(df, data_config, model_id, seed):\n",
    "\n",
    "    if 'prevalence' in data_config:\n",
    "        df = subsample_with_prevalence(df, eval(data_config['prevalence']), seed)\n",
    "\n",
    "    if logging.root.isEnabledFor(logging.DEBUG):\n",
    "        logging.debug(\n",
    "            'Model %s: Dataset with %s Examples (%s fraud, %s non fraud)',\n",
    "            pad_int(model_id),\n",
    "            len(df),\n",
    "            len(df[df['fraud_bool'] == 1]),\n",
    "            len(df[df['fraud_bool'] == 0])\n",
    "        )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6b4b7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_categorical(train_df, val_df, discrete_columns):\n",
    "\n",
    "    categorical_columns = np.intersect1d(discrete_columns, CATEGORICAL_FEATURES)\n",
    "\n",
    "    for column in categorical_columns:\n",
    "        train_unique = train_df[column].unique()\n",
    "        val_unique = val_df[column].unique()\n",
    "        nans = np.setdiff1d(val_unique, train_unique)\n",
    "        val_df.loc[val_df[column].isin(nans), [column]] = np.nan\n",
    "\n",
    "    train_dummy = pd.get_dummies(train_df, columns=categorical_columns, dummy_na=True)\n",
    "    val_dummy = pd.get_dummies(val_df, columns=categorical_columns, dummy_na=True)\n",
    "\n",
    "    for unseen_column in np.setdiff1d(train_dummy.columns, val_dummy.columns):\n",
    "        val_dummy[unseen_column] = 0\n",
    "\n",
    "    return train_dummy, val_dummy\n",
    "\n",
    "def split(train_df, val_df, target):\n",
    "    train_x = train_df.drop(columns=[target])\n",
    "    train_y = train_df[target]\n",
    "    val_x = val_df.drop(columns=[target])\n",
    "    val_y = val_df[target]\n",
    "    return train_x, train_y, val_x, val_y\n",
    "\n",
    "def preprocess_and_split(train_df, val_df, discrete_columns, target):\n",
    "    train_dummy_df, val_dummy_df = preprocess_categorical(train_df, val_df, discrete_columns)\n",
    "    return split(train_dummy_df, val_dummy_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd336d1d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def class_index(model, class_value):\n",
    "    return np.argwhere(model.classes_ == class_value)[0]\n",
    "\n",
    "\n",
    "def prediction_probabilities(model, x):\n",
    "    return model.predict_proba(x)[:, class_index(model, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1218992",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ordinal_encode(train_df, val_df, categorical_features):\n",
    "    for f in categorical_features:\n",
    "        enc = preprocessing.OrdinalEncoder()\n",
    "        train_df[f] = enc.fit_transform(train_df[[f]])\n",
    "        val_df[f] = enc.fit_transform(val_df[[f]])\n",
    "    return train_df, val_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f042403",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compile_results(\n",
    "        real_fprs,\n",
    "        real_tprs,\n",
    "        real_thresholds,\n",
    "        synthetic_train_fprs,\n",
    "        synthetic_train_tprs,\n",
    "        synthetic_train_thresholds,\n",
    "        synthetic_val_fprs,\n",
    "        synthetic_val_tprs,\n",
    "        synthetic_val_thresholds,\n",
    "        synthetic_both_fprs,\n",
    "        synthetic_both_tprs,\n",
    "        synthetic_both_thresholds):\n",
    "\n",
    "    records = []\n",
    "    for i, results in enumerate(zip(real_fprs, real_tprs, real_thresholds), start=1):\n",
    "        for fpr, tpr, threshold in zip(*results):\n",
    "            records.append((i, fpr, tpr, threshold, 'real'))\n",
    "\n",
    "    for j, results in enumerate(zip(synthetic_train_fprs, synthetic_train_tprs, synthetic_train_thresholds), start=i+1):\n",
    "        for fpr, tpr, threshold in zip(*results):\n",
    "            records.append((j, fpr, tpr, threshold, 'synthetic-train'))\n",
    "\n",
    "    for k, results in enumerate(zip(synthetic_val_fprs, synthetic_val_tprs, synthetic_val_thresholds), start=j+1):\n",
    "        for fpr, tpr, threshold in zip(*results):\n",
    "            records.append((k, fpr, tpr, threshold, 'synthetic-val'))\n",
    "\n",
    "    for n, results in enumerate(zip(synthetic_both_fprs, synthetic_both_tprs, synthetic_both_thresholds), start=k+1):\n",
    "        for fpr, tpr, threshold in zip(*results):\n",
    "            records.append((n, fpr, tpr, threshold, 'synthetic-both'))\n",
    "\n",
    "    return pd.DataFrame.from_records(records, columns=['run_id', 'fpr', 'tpr', 'threshold', 'discrimination'])\n",
    "\n",
    "\n",
    "def summarize_results(\n",
    "        real_fprs,\n",
    "        real_tprs,\n",
    "        real_thresholds,\n",
    "        synthetic_train_fprs,\n",
    "        synthetic_train_tprs,\n",
    "        synthetic_train_thresholds,\n",
    "        synthetic_val_fprs,\n",
    "        synthetic_val_tprs,\n",
    "        synthetic_val_thresholds,\n",
    "        synthetic_both_fprs,\n",
    "        synthetic_both_tprs,\n",
    "        synthetic_both_thresholds):\n",
    "\n",
    "    def compute_avg_tpr_and_threshold(fprs, tprs, thresholds):\n",
    "        avg_tpr = 0\n",
    "        avg_threshold = 0\n",
    "\n",
    "        for run_fprs, run_tprs, run_thresholds in zip(fprs, tprs, thresholds):\n",
    "            target_fpr_index = np.argwhere(run_fprs <= TARGET_FPR).ravel()[-1]\n",
    "            avg_tpr += run_tprs[target_fpr_index] / N_RUNS\n",
    "            avg_threshold += run_thresholds[target_fpr_index] / N_RUNS\n",
    "\n",
    "        return avg_tpr, avg_threshold\n",
    "\n",
    "    avg_real_tpr, avg_real_threshold = \\\n",
    "        compute_avg_tpr_and_threshold(real_fprs, real_tprs, real_thresholds)\n",
    "\n",
    "    avg_synthetic_train_tpr, avg_synthetic_train_threshold = \\\n",
    "        compute_avg_tpr_and_threshold(synthetic_train_fprs, synthetic_train_tprs, synthetic_train_thresholds)\n",
    "\n",
    "    avg_synthetic_val_tpr, avg_synthetic_val_threshold = \\\n",
    "        compute_avg_tpr_and_threshold(synthetic_val_fprs, synthetic_val_tprs, synthetic_val_thresholds)\n",
    "\n",
    "    avg_synthetic_both_tpr, avg_synthetic_both_threshold = \\\n",
    "        compute_avg_tpr_and_threshold(synthetic_both_fprs, synthetic_both_tprs, synthetic_both_thresholds)\n",
    "\n",
    "    return (\n",
    "        avg_real_tpr,\n",
    "        avg_real_threshold,\n",
    "        avg_synthetic_train_tpr,\n",
    "        avg_synthetic_train_threshold,\n",
    "        avg_synthetic_val_tpr,\n",
    "        avg_synthetic_val_threshold,\n",
    "        avg_synthetic_both_tpr,\n",
    "        avg_synthetic_both_threshold\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b18ca9a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_instance(run_config: RunConfig):\n",
    "\n",
    "    model_id = run_config.model_id\n",
    "\n",
    "    train_df = run_config.train_df\n",
    "    val_df = run_config.val_df\n",
    "    discrete_columns = run_config.discrete_columns\n",
    "\n",
    "    model_run_dir = pathlib.Path(run_config.model_run_dir)\n",
    "\n",
    "    config = run_config.config\n",
    "    config_save_path = config_path(model_run_dir, model_id)\n",
    "    model_save_path = model_path(model_run_dir, model_id)\n",
    "    model_evaluation_save_path = model_evaluation_path(model_run_dir, model_id)\n",
    "    train_data_save_path = train_dataset_path(model_run_dir, model_id)\n",
    "    synthetic_data_save_path = synthetic_dataset_path(model_run_dir, model_id)\n",
    "\n",
    "    run_stdout_path = stdout_path(model_run_dir, model_id)\n",
    "    run_stderr_path = stderr_path(model_run_dir, model_id)\n",
    "\n",
    "    seed = run_config.seed\n",
    "\n",
    "    logging.info('Model %s: Training started', pad_int(model_id))\n",
    "    logging.debug('Model %s: Config %s', pad_int(model_id), config)\n",
    "    logging.debug('Model %s: Saved config to \\'%s\\'', pad_int(model_id), config_save_path)\n",
    "    logging.debug('Model %s: Stdout redirected to \\'%s\\'', pad_int(model_id), run_stdout_path)\n",
    "    logging.debug('Model %s: Stderr redirected to \\'%s\\'', pad_int(model_id), run_stderr_path)\n",
    "\n",
    "    data_config = config['data']\n",
    "    model_config = config['model']\n",
    "\n",
    "\n",
    "    df = pd.concat((train_df, val_df))\n",
    "    df = utils.shuffle(df)\n",
    "\n",
    "    df = apply_config_to_data(df, data_config, model_id, seed)\n",
    "\n",
    "    discrete_columns = copy.copy(discrete_columns)\n",
    "\n",
    "\n",
    "    os.mkdir(model_run_dir)\n",
    "\n",
    "    df.to_csv(train_data_save_path)\n",
    "    logging.debug('Model %s: Training data saved to %s', pad_int(model_id), train_data_save_path)\n",
    "\n",
    "    with open(config_save_path, 'w') as fd:\n",
    "        yaml.safe_dump(config, stream=fd, default_flow_style=False)\n",
    "\n",
    "    model = ctgan.CTGANSynthesizer(**model_config)\n",
    "\n",
    "    with open(run_stdout_path, 'w') as out_fd, open(run_stderr_path, 'w') as err_fd:\n",
    "        with redirect_stdout(out_fd), redirect_stderr(err_fd):\n",
    "            model.fit(df, discrete_columns)\n",
    "\n",
    "    model.save(model_save_path)\n",
    "\n",
    "    logging.info('Model %s: Saved model to \\'%s\\'', pad_int(model_id), model_save_path)\n",
    "\n",
    "    synthetic_df = model.sample(len(df))\n",
    "    synthetic_df.to_csv(synthetic_data_save_path)\n",
    "\n",
    "    logging.info('Model %s: Saved synthetic dataset to \\'%s\\'', pad_int(model_id), synthetic_data_save_path)\n",
    "\n",
    "    return model_id, synthetic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659f89ac",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    run_dir = pathlib.Path(args['run_dir'])\n",
    "\n",
    "    config_path = args['config_path']\n",
    "    n_procs = args['n_procs']\n",
    "    devices = args['devices']\n",
    "    dry_run = args['dry_run']\n",
    "    seed = args['seed']\n",
    "    n_trials = args['n_trials']\n",
    "\n",
    "    configure_logging(args['log_level'])\n",
    "\n",
    "    if seed:\n",
    "        seed = int(seed)\n",
    "        logging.info('Using seed value: %s', seed)\n",
    "\n",
    "    create_run_dir(run_dir)\n",
    "    \n",
    "    datasets_config, sweep_params = read_configurations(config_path)\n",
    "\n",
    "    data_sweep_params = sweep_params['data']\n",
    "    model_sweep_params = sweep_params['model']\n",
    "\n",
    "    run_configs = build_run_configs(\n",
    "        run_dir,\n",
    "        datasets_config,\n",
    "        data_sweep_params,\n",
    "        model_sweep_params,\n",
    "        devices,\n",
    "        n_trials,\n",
    "        seed\n",
    "    )\n",
    "    \n",
    "    dfs = []\n",
    "    with mp.Pool(n_procs) as pool:\n",
    "        for synthetic_df in pool.imap_unordered(run_instance, run_configs):\n",
    "            if not dry_run:\n",
    "                dfs.append(synthetic_df)\n",
    "\n",
    "    logging.info('Finished Successfully')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}